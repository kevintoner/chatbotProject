{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build an Article ChatBot"
      ],
      "metadata": {
        "id": "snvPRRiO7Z_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use any LLM model.\n",
        "\n",
        "Build a bot that will take a query and answer from blogs on the internet.\n",
        "1. Take a query as input.\n",
        "2. Get relevant articles from the internet.\n",
        "3. Find the correct answer from the article contents.\n",
        "4. Reply with the answer and link of the article.\n",
        "\n",
        "Please use Google Colab to complete this assignment. \\\n",
        "If you face any problems with colab, you can write a python script and share that."
      ],
      "metadata": {
        "id": "UowMoQp1i6O3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Z1L46vpCMWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The solution makes use of the **Google Search API**, **LangChain** and uses **RAG** (Retrieval Augmented Generation)\n",
        "\n",
        "- Relevant articles are gathered from the internet using the Google Search API - the users query is used along with \" inurl:blog\" appended on to the end of the string in order to ensure only blogs appear in the search results.\n",
        "\n",
        "- Beautiful Soup was used to webscrape the content from the webpages at each of these links.\n",
        "\n",
        "(Please note: The GPT-3.5 is utlitized because it has a knowledge cutoff in September 2021 ([Source](https://help.openai.com/en/articles/8555514-gpt-3-5-turbo-updates)), therefore asking questions where the answer is not known until after this date will ensure that the answers are completely from the internet blogs and that the model does not \"cheat\".)"
      ],
      "metadata": {
        "id": "r4LGHGdbi8Zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><div>\n",
        "<img src=\"https://www.researchgate.net/publication/371582328/figure/fig4/AS:11431281168418756@1686961053226/Google-Cloud-Platform-logo.ppm\" width=\"250\" height=\"auto\">\n",
        "<img src=\"https://datascientest.com/en/wp-content/uploads/sites/9/2024/01/beautiful-soup.png\" width=\"250\" height=\"auto\">\n",
        "<img src=\"https://deepsense.ai/wp-content/uploads/2023/10/LangChain-announces-partnership-with-deepsense.jpeg\" width=\"250\" height=\"auto\" style=\"margin-right: 20px;\">\n",
        "<img src=\"https://static.vecteezy.com/system/resources/previews/021/059/825/original/chatgpt-logo-chat-gpt-icon-on-green-background-free-vector.jpg\" width=\"100\" height=\"auto\">\n",
        "</div></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "PEfS5Xrm4RKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Qo1qIH42I7JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai\n",
        "%pip install unstructured\n",
        "%pip install chromadb\n",
        "%pip install tiktoken\n",
        "%pip install langchain"
      ],
      "metadata": {
        "id": "_eM_Fwx2wDeL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n9mzS-qo5Sg0"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from bs4 import BeautifulSoup\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "import openai\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Webpage Content\n",
        "In this section the relevant blog article links will be collected using the Google Search API."
      ],
      "metadata": {
        "id": "Taj0IfRtF44s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example search_query\n",
        "search_query = \"Which team won the Premier Leauge in 2023?\""
      ],
      "metadata": {
        "id": "wPollyT1wPAI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Search API\n",
        "API_KEY = \"XXX\"\n",
        "SEARCH_ENGINE_ID = \"XXX\""
      ],
      "metadata": {
        "id": "9ugmqU2TDlgX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gatherLinks(search_query,numLinks=5):\n",
        "\n",
        "  # Limit the search results to blogs\n",
        "  search_query += \" inurl:blog\"\n",
        "\n",
        "  url = \"https://www.googleapis.com/customsearch/v1\"\n",
        "  params = {\n",
        "      \"q\": search_query,\n",
        "      \"key\": API_KEY,\n",
        "      \"cx\": SEARCH_ENGINE_ID,\n",
        "      \"num\": numLinks,\n",
        "  }\n",
        "\n",
        "  response = requests.get(url, params=params)\n",
        "  results = response.json()\n",
        "\n",
        "  urlList = []\n",
        "\n",
        "  if \"items\" in results:\n",
        "      for i in range(min(numLinks, len(results[\"items\"]))):\n",
        "          urlList.append(results[\"items\"][i][\"link\"])\n",
        "  else:\n",
        "      print(\"No search results found.\")\n",
        "\n",
        "  return urlList"
      ],
      "metadata": {
        "id": "OzLrf79YENO5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gatherContent(urlList):\n",
        "  urlContentList = []\n",
        "\n",
        "  for url in urlList:\n",
        "    try:\n",
        "        # Send a GET request to the URL\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Create a BeautifulSoup object to parse the HTML\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Find the <body> element\n",
        "        body_content = soup.find(\"body\")\n",
        "\n",
        "        # Check if the <body> element was found\n",
        "        if body_content:\n",
        "            # Extract the text from the <body> element\n",
        "            text = body_content.get_text()\n",
        "            urlContentList.append(text[:10000]) # Limit number of words\n",
        "        else:\n",
        "            print(f\"No <body> element found for URL: {url}\")\n",
        "            urlContentList.append(\"\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error occurred while retrieving URL: {url}\")\n",
        "        print(f\"Error message: {str(e)}\")\n",
        "  return urlContentList"
      ],
      "metadata": {
        "id": "7iOoHBlFenYT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urlList = gatherLinks(search_query)\n",
        "urlContentList = gatherContent(urlList)"
      ],
      "metadata": {
        "id": "75GMpU3EmJck"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the content of each of the webpages into individual markdown files\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "output_dir = \"data\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save each URL content to a separate markdown file\n",
        "for i, url_content in enumerate(urlContentList):\n",
        "    file_name = f\"{urlList[i].replace('https://', '').replace('/', '_')}.md\"\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(url_content)\n",
        "    print(f\"Saved content for {urlList[i]} to {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_CT7UKOxIJB",
        "outputId": "9b6df98e-7f08-43f9-9ac4-25162f2b0398"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved content for https://www.premierleague.com/matchweek/12284/blog to data/www.premierleague.com_matchweek_12284_blog.md\n",
            "Saved content for https://weaintgotnohistory.sbnation.com/2023/11/25/23975423/newcastle-united-chelsea-premier-league-live-stream-time-tv-how-watch-online-live-blog-highlights to data/weaintgotnohistory.sbnation.com_2023_11_25_23975423_newcastle-united-chelsea-premier-league-live-stream-time-tv-how-watch-online-live-blog-highlights.md\n",
            "Saved content for https://www.premierleague.com/matchweek/12296/blog to data/www.premierleague.com_matchweek_12296_blog.md\n",
            "Saved content for https://weaintgotnohistory.sbnation.com/2023/10/28/23935994/chelsea-brentford-premier-league-live-stream-time-tv-how-watch-online-live-blog-highlights to data/weaintgotnohistory.sbnation.com_2023_10_28_23935994_chelsea-brentford-premier-league-live-stream-time-tv-how-watch-online-live-blog-highlights.md\n",
            "Saved content for https://www.venasolutions.com/blog/richest-premier-league-clubs to data/www.venasolutions.com_blog_richest-premier-league-clubs.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer Question\n",
        "\n",
        "To answer the question, the ChatGPT API will be utilised"
      ],
      "metadata": {
        "id": "WiG-MjeDUSgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 1\n",
        "\n",
        "In this approach, a for loop is utilized, where in each iteration the content from one of the webpages is passed, until the chatbot can answer the query."
      ],
      "metadata": {
        "id": "QHEVMNPqt08P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"XXX\""
      ],
      "metadata": {
        "id": "Mz0oKHPdG1CR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return zzz, as this will never show up in the correct answer\n",
        "\n",
        "for i in range(0, len(urlContentList)):\n",
        "  completion = openai.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": f\"Answer the question: {search_query} \\n---\\n using the content passed on, if you cant answer simply return 'zzz' only.\"},\n",
        "          {\"role\": \"user\", \"content\": urlContentList[i]},\n",
        "      ],\n",
        "  )\n",
        "  result = completion.choices[0].message.content\n",
        "\n",
        "  if \"zzz\" not in result.lower():\n",
        "    print(completion.choices[0].message.content)\n",
        "    print(f\"Source: {urlList[i]}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KISCZVIPGF7-",
        "outputId": "9922ccc2-4787-4482-e12a-221fc78bc2ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manchester City won the Premier League in 2023.\n",
            "Source: https://www.premierleague.com/matchweek/12284/blog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 2\n",
        "\n",
        "Shoutout to this video for helping:\n",
        "\n",
        "[RAG + Langchain Python Project: Easy AI/Chat For Your Docs](https://www.youtube.com/watch?v=tcqEUSNCn8I)\n",
        "\n",
        "In this approach, RAG is used. The documents are broken into chunks, and the most relevant chunks to the query are got and are used to answer the query."
      ],
      "metadata": {
        "id": "GsU0-NGktuEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the markdown files from the data folder\n",
        "loader = DirectoryLoader(\"data\", glob=\"*.md\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "PW4XAOztvzjy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=500,\n",
        "    length_function=len,\n",
        "    add_start_index=True\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjbMsBNIyvyf",
        "outputId": "5767acdf-c841-4df6-f1a5-a22d84c56139"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 58 documents into 814 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chroma: This is a vector database library that is used for efficient storage and retrieval of high-dimensional data, such as text embeddings.\n",
        "CHROMA_PATH = \"chroma\""
      ],
      "metadata": {
        "id": "a06vyhwRyN7k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Answer the question based on the above context: {question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5s0V8jgR3PJ4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete if already exists\n",
        "if os.path.exists(CHROMA_PATH):\n",
        "  shutil.rmtree(CHROMA_PATH)"
      ],
      "metadata": {
        "id": "JpiWl4a-1Ouw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_documents(chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH)\n",
        "db.persist()\n",
        "print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi_XcUw81zbn",
        "outputId": "8ebb36fb-1ccc-4936-be11-de318bda48cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 814 chunks to chroma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the 5 results which are most relevant to the search_query\n",
        "results = db.similarity_search_with_relevance_scores(search_query, k=5)\n",
        "\n",
        "if len(results) == 0 or results[0][1] < 0.7:\n",
        "  print(f\"Unable to find matching results.\")"
      ],
      "metadata": {
        "id": "8uAJ4Zob2jZr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
        "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "prompt = prompt_template.format(context=context_text, question=search_query)\n",
        "model = ChatOpenAI()\n",
        "response_text = model.predict(prompt)\n",
        "\n",
        "# Convert file names back to url link\n",
        "def find_most_similar_link(source, html_list):\n",
        "    max_similarity = 0\n",
        "    most_similar_link = None\n",
        "\n",
        "    for link in html_list:\n",
        "        similarity = SequenceMatcher(None, source, link).ratio()\n",
        "        if similarity > max_similarity:\n",
        "            max_similarity = similarity\n",
        "            most_similar_link = link\n",
        "\n",
        "    return most_similar_link\n",
        "\n",
        "sources = []\n",
        "for doc, score in results:\n",
        "    source = doc.metadata.get(\"source\", None)\n",
        "    if source:\n",
        "        most_similar_link = find_most_similar_link(source, urlList)\n",
        "        if most_similar_link:\n",
        "            sources.append(f\"- {most_similar_link} (Score: {score:.2f})\")\n",
        "        else:\n",
        "            sources.append(f\"- {source} (Score: {score:.2f})\")\n",
        "\n",
        "sources_text = \"\\n\".join(sources)\n",
        "formatted_response = f\"Response: {response_text}\\n\\nSources:\\n{sources_text}\"\n",
        "print(formatted_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpvTWKPN0nQs",
        "outputId": "a3554450-31fc-492c-904e-c146caea964a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Manchester City won the Premier League in 2023.\n",
            "\n",
            "Sources:\n",
            "- https://www.venasolutions.com/blog/richest-premier-league-clubs (Score: 0.77)\n",
            "- https://www.venasolutions.com/blog/richest-premier-league-clubs (Score: 0.76)\n",
            "- https://weaintgotnohistory.sbnation.com/2023/11/25/23975423/newcastle-united-chelsea-premier-league-live-stream-time-tv-how-watch-online-live-blog-highlights (Score: 0.75)\n",
            "- https://weaintgotnohistory.sbnation.com/2023/10/28/23935994/chelsea-brentford-premier-league-live-stream-time-tv-how-watch-online-live-blog-highlights (Score: 0.75)\n",
            "- https://weaintgotnohistory.sbnation.com/2023/10/28/23935994/chelsea-brentford-premier-league-live-stream-time-tv-how-watch-online-live-blog-highlights (Score: 0.75)\n"
          ]
        }
      ]
    }
  ]
}
